CN:
  anneal_clr_by_factor: 0.9
  backward_iters: 10
  clip_obs: 20
  cn_acs_select_name: null
  cn_batch_size: null
  cn_eps: 1.0e-05
  cn_layers:
  - 20
  cn_learning_rate: 0.05
  cn_normalize: false
  cn_obs_select_name: null
  cn_reg_coeff: 0.5
  cn_target_kl_new_old: 2.5
  cn_target_kl_old_new: 10
  no_importance_sampling: false
  per_step_importance_sampling: true
  train_gail_lambda: false
PPO:
  batch_size: 64
  budget: 0
  clip_range: 0.2
  clip_range_cost_vf: null
  clip_range_reward_vf: null
  cost_gae_lambda: 0.95
  cost_gamma: 0.99
  cost_vf_coef: 0.5
  cost_vf_layers:
  - 64
  - 64
  derivative_control_coeff: 0
  derivative_cost_ema_alpha: 0.5
  ent_coef: 0.0
  eval_every: 2048
  forward_timesteps: 200000
  integral_control_coeff: 0.0001
  learning_rate: 0.0003
  max_grad_norm: 0.5
  n_epochs: 10
  n_steps: 2048
  penalty_initial_value: 1
  penalty_learning_rate: 0.1
  pid_delay: 1
  policy_layers:
  - 64
  - 64
  policy_name: TwoCriticsMlpPolicy
  proportional_control_coeff: 10
  proportional_cost_ema_alpha: 0.5
  reset_policy: false
  reward_gae_lambda: 0.95
  reward_gamma: 0.99
  reward_vf_coef: 0.5
  reward_vf_layers:
  - 64
  - 64
  sde_sample_freq: -1
  shared_layers: null
  target_kl: 0.01
  use_curiosity_driven_exploration: false
  use_sde: false
  warmup_timesteps: false
device: cuda
env:
  config_path: null
  cost_gamma: 0.99
  cost_info_str: cost
  dont_normalize_cost: false
  dont_normalize_obs: false
  dont_normalize_reward: false
  eval_env_id: HCWithPos-v0
  num_threads: 5
  record_info_input_dims:
  - 0
  record_info_names:
  - xpos
  reward_gamma: 0.99
  save_dir: ../save_model
  train_env_id: HCWithPos-v0
  use_cost: true
  visualize_info_ranges:
  - - -30
    - 30
group: ICRL
multi_env: true
running:
  expert_path: ../data/expert_data/HCWithPos-New/
  expert_rollouts: 10
  n_eval_episodes: 10
  n_iters: 30
  sample_rollouts: 10
  save_every: 5
  store_by_game: false
  store_sample_rollouts: null
  use_buffer: false
task: ICRL-HC
verbose: 2
